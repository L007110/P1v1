#  å¿«é€Ÿè®­ç»ƒæµ‹è¯•
import torch
from DebugPrint import debug_print


def quick_training_test():
    """å¿«é€Ÿè®­ç»ƒæµ‹è¯•"""
    debug_print("=== å¿«é€Ÿè®­ç»ƒæµ‹è¯• ===")

    try:
        from Main import rl
        from Parameters import global_dqn_list
        from Topology import formulate_global_list_dqn

        # è®¾ç½®è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        debug_print(f"è®­ç»ƒè®¾å¤‡: {device}")

        # åˆå§‹åŒ–DQN
        formulate_global_list_dqn(global_dqn_list, device)
        debug_print(f"åˆå§‹åŒ–äº† {len(global_dqn_list)} ä¸ªDQN")

        # æµ‹è¯•GNNå¢å¼º
        from GNNIntegration import global_gnn_manager
        if global_gnn_manager.use_gnn:
            debug_print("âœ… GNNå¢å¼ºå·²å¯ç”¨")
            for dqn in global_dqn_list[:2]:  # åªå¢å¼ºå‰2ä¸ª
                enhanced = global_gnn_manager.enhance_dqn_with_gnn(dqn)
                debug_print(f"  DQN {dqn.dqn_id} -> {enhanced.__class__.__name__}")
        else:
            debug_print("â„¹ï¸ GNNå¢å¼ºæœªå¯ç”¨")

        debug_print("ğŸ‰ è®­ç»ƒç¯å¢ƒå°±ç»ªï¼")
        return True

    except Exception as e:
        debug_print(f"âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    if quick_training_test():
        debug_print("ğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œ: python Main.py")
    else:
        debug_print("âŒ éœ€è¦æ£€æŸ¥è®­ç»ƒé…ç½®")