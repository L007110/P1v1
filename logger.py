<<<<<<< HEAD
# -*- coding: utf-8 -*-
# logger.py
import logging
import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict


class TrainingLogger:
    """
    ä¸“ä¸šçš„è®­ç»ƒæ—¥å¿—è®°å½•å™¨ - ä¿®å¤ç‰ˆ
    """

    def __init__(self, log_dir="training_results"):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)

        self._setup_logging()
        self._init_metrics_storage()

        self.logger.info("TrainingLogger initialized")
        self.logger.info(f"Log directory: {os.path.abspath(log_dir)}")

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        self.logger = logging.getLogger('RL_Training')
        self.logger.setLevel(logging.INFO)

        # é˜²æ­¢é‡å¤æ·»åŠ handler
        if self.logger.handlers:
            self.logger.handlers.clear()

        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y/%m/%d %H:%M:%S'
        )

        # æ–‡ä»¶handler
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_handler = logging.FileHandler(f'{self.log_dir}/training_{timestamp}.log')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(formatter)

        # æ§åˆ¶å°handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(formatter)

        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

    def _init_metrics_storage(self):
        """åˆå§‹åŒ–æŒ‡æ ‡å­˜å‚¨ç»“æ„"""
        self.metrics = {
            'epoch': [],
            'cumulative_reward': [],
            'mean_loss': [],
            'mean_delay': [],
            'mean_snr': [],
            'vehicle_count': [],
            'timestamp': []
        }

        self.dqn_metrics = defaultdict(lambda: {
            'loss': [],
            'reward': [],
            'epsilon': [],
            'vehicle_count': [],
            'snr': [],
            'delay': []
        })

        self.training_stats = {
            'start_time': datetime.now(),
            'total_epochs': 0,
            'best_reward': -float('inf'),
            'best_epoch': 0,
            'convergence_epoch': None
        }

    def _convert_tensor_to_float(self, value):
        """å®‰å…¨è½¬æ¢PyTorchå¼ é‡ä¸ºfloat"""
        if hasattr(value, 'detach'):
            # å¦‚æœæ˜¯PyTorchå¼ é‡
            return value.detach().item() if value.numel() == 1 else float(value.detach().mean())
        elif hasattr(value, 'numpy'):
            # å¦‚æœæ˜¯TensorFlowå¼ é‡æˆ–å…¶ä»–
            return float(value)
        else:
            # å¦‚æœæ˜¯æ™®é€šæ•°å€¼
            return float(value)

    def _convert_tensor_to_int(self, value):
        """å®‰å…¨è½¬æ¢PyTorchå¼ é‡ä¸ºint"""
        if hasattr(value, 'detach'):
            # å¦‚æœæ˜¯PyTorchå¼ é‡
            return int(value.detach().item() if value.numel() == 1 else int(value.detach().mean()))
        elif hasattr(value, 'numpy'):
            # å¦‚æœæ˜¯TensorFlowå¼ é‡æˆ–å…¶ä»–
            return int(value)
        else:
            # å¦‚æœæ˜¯æ™®é€šæ•°å€¼
            return int(value)

    def log_epoch(self, epoch, cumulative_reward, mean_loss, mean_delay, mean_snr, vehicle_count):
        """è®°å½•æ¯ä¸ªepochçš„å…¨å±€æŒ‡æ ‡ - ä¿®å¤ç‰ˆ"""
        # å®‰å…¨è½¬æ¢æ‰€æœ‰å€¼ä¸ºæ­£ç¡®çš„ç±»å‹
        cumulative_reward_float = self._convert_tensor_to_float(cumulative_reward)
        mean_loss_float = self._convert_tensor_to_float(mean_loss)
        mean_delay_float = self._convert_tensor_to_float(mean_delay)
        mean_snr_float = self._convert_tensor_to_float(mean_snr)
        vehicle_count_int = self._convert_tensor_to_int(vehicle_count)

        self.metrics['epoch'].append(epoch)
        self.metrics['cumulative_reward'].append(cumulative_reward_float)
        self.metrics['mean_loss'].append(mean_loss_float)
        self.metrics['mean_delay'].append(mean_delay_float)
        self.metrics['mean_snr'].append(mean_snr_float)
        self.metrics['vehicle_count'].append(vehicle_count_int)
        self.metrics['timestamp'].append(datetime.now())

        # æ›´æ–°è®­ç»ƒç»Ÿè®¡
        self.training_stats['total_epochs'] = epoch
        if cumulative_reward_float > self.training_stats['best_reward']:
            self.training_stats['best_reward'] = cumulative_reward_float
            self.training_stats['best_epoch'] = epoch

        self.logger.info(
            f"Epoch {epoch:4d} | "
            f"Loss: {mean_loss_float:7.4f} | "
            f"Reward: {cumulative_reward_float:8.3f} | "
            f"Delay: {mean_delay_float:8.6f}s | "
            f"SNR: {mean_snr_float:6.2f}dB | "
            f"Vehicles: {vehicle_count_int:3d}"
        )

    def log_dqn_performance(self, dqn_id, metrics_dict):
        """è®°å½•å•ä¸ªDQNçš„æ€§èƒ½æŒ‡æ ‡ - ä¿®å¤ç‰ˆ"""
        # å®‰å…¨è½¬æ¢æ‰€æœ‰æŒ‡æ ‡å€¼ä¸ºæ­£ç¡®çš„ç±»å‹
        safe_metrics = {}
        for metric_name, value in metrics_dict.items():
            if metric_name in ['vehicle_count']:
                # è½¦è¾†æ•°é‡éœ€è¦æ•´æ•°
                safe_metrics[metric_name] = self._convert_tensor_to_int(value)
            else:
                # å…¶ä»–æŒ‡æ ‡ç”¨æµ®ç‚¹æ•°
                safe_metrics[metric_name] = self._convert_tensor_to_float(value)

        for metric_name, value in safe_metrics.items():
            if metric_name in self.dqn_metrics[dqn_id]:
                self.dqn_metrics[dqn_id][metric_name].append(value)

        # ä¿®å¤æ ¼å¼åŒ–å­—ç¬¦ä¸² - æ ¹æ®ç±»å‹ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼
        vehicle_count = safe_metrics.get('vehicle_count', 0)
        if isinstance(vehicle_count, (int, np.integer)):
            vehicle_format = f"{vehicle_count:2d}"
        else:
            vehicle_format = f"{int(vehicle_count):2d}"

        self.logger.debug(
            f"DQN {dqn_id:2d} | "
            f"Loss: {safe_metrics.get('loss', 0):7.4f} | "
            f"Reward: {safe_metrics.get('reward', 0):8.3f} | "
            f"Epsilon: {safe_metrics.get('epsilon', 0):5.3f} | "
            f"Vehicles: {vehicle_format}"
        )

    def log_convergence(self, epoch, final_loss):
        """è®°å½•æ”¶æ•›ä¿¡æ¯"""
        final_loss_float = self._convert_tensor_to_float(final_loss)
        self.training_stats['convergence_epoch'] = epoch
        self.training_stats['final_loss'] = final_loss_float

        self.logger.info(f"ğŸš€ CONVERGENCE ACHIEVED at epoch {epoch} with final loss {final_loss_float:.6f}")

    def _ensure_consistent_array_lengths(self):
        """ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´ - ä¿®å¤é•¿åº¦ä¸ä¸€è‡´é—®é¢˜"""
        max_length = max(len(arr) for arr in self.metrics.values() if arr)

        for key in self.metrics:
            current_length = len(self.metrics[key])
            if current_length < max_length:
                # ç”¨æœ€åä¸€ä¸ªå€¼å¡«å……ç¼ºå¤±çš„æ•°æ®
                fill_value = self.metrics[key][-1] if self.metrics[key] else 0
                self.metrics[key].extend([fill_value] * (max_length - current_length))
                self.logger.warning(f"Fixed array length for {key}: {current_length} -> {max_length}")

    def save_metrics_to_csv(self):
        """å°†æŒ‡æ ‡ä¿å­˜ä¸ºCSVæ–‡ä»¶ - ä¿®å¤ç‰ˆ"""
        try:
            # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
            self._ensure_consistent_array_lengths()

            # ä¿å­˜å…¨å±€æŒ‡æ ‡
            global_df = pd.DataFrame(self.metrics)
            global_csv_path = f"{self.log_dir}/global_metrics.csv"
            global_df.to_csv(global_csv_path, index=False)
            self.logger.info(f"Global metrics saved to {global_csv_path}")

            # ä¿å­˜DQNæŒ‡æ ‡
            dqn_count = 0
            for dqn_id, metrics in self.dqn_metrics.items():
                if metrics and metrics['loss']:  # åªä¿å­˜æœ‰æ•°æ®çš„DQN
                    # ç¡®ä¿DQNæŒ‡æ ‡æ•°ç»„é•¿åº¦ä¸€è‡´
                    max_dqn_length = max(len(arr) for arr in metrics.values() if arr)
                    for key in metrics:
                        if len(metrics[key]) < max_dqn_length:
                            fill_value = metrics[key][-1] if metrics[key] else 0
                            metrics[key].extend([fill_value] * (max_dqn_length - len(metrics[key])))

                    dqn_df = pd.DataFrame(metrics)
                    dqn_df['epoch'] = range(1, len(dqn_df) + 1)
                    dqn_csv_path = f"{self.log_dir}/dqn_{dqn_id}_metrics.csv"
                    dqn_df.to_csv(dqn_csv_path, index=False)
                    dqn_count += 1

            self.logger.info(f"Saved metrics for {dqn_count} DQNs to CSV files")

        except Exception as e:
            self.logger.error(f"Error saving CSV: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

    def generate_plots(self):
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨ - ä¿®å¤ç‰ˆ"""
        try:
            # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
            self._ensure_consistent_array_lengths()

            # è®¾ç½®ç»˜å›¾æ ·å¼
            plt.style.use('default')
            sns.set_palette("husl")

            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(3, 2, figsize=(15, 12))
            fig.suptitle('Training Performance Metrics', fontsize=16, fontweight='bold')

            # ç¡®ä¿æœ‰æ•°æ®å¯ç»˜åˆ¶
            if not self.metrics['epoch']:
                self.logger.warning("No data available for plotting")
                return

            # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå®‰å…¨è½¬æ¢ï¼‰
            epochs = np.array(self.metrics['epoch'])
            mean_loss = np.array(self.metrics['mean_loss'])
            cumulative_reward = np.array(self.metrics['cumulative_reward'])
            mean_delay = np.array(self.metrics['mean_delay'])
            mean_snr = np.array(self.metrics['mean_snr'])
            vehicle_count = np.array(self.metrics['vehicle_count'])

            # 1. æŸå¤±æ›²çº¿
            axes[0, 0].plot(epochs, mean_loss, 'b-', linewidth=2)
            axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)
            if len(mean_loss) > 0 and max(mean_loss) > min(mean_loss) * 10:
                axes[0, 0].set_yscale('log')

            # 2. å¥–åŠ±æ›²çº¿
            axes[0, 1].plot(epochs, cumulative_reward, 'g-', linewidth=2)
            axes[0, 1].set_title('Cumulative Reward', fontsize=14, fontweight='bold')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Reward')
            axes[0, 1].grid(True, alpha=0.3)

            # 3. å»¶è¿Ÿæ›²çº¿
            axes[1, 0].plot(epochs, mean_delay, 'r-', linewidth=2)
            axes[1, 0].set_title('Mean Delay', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Delay (s)')
            axes[1, 0].grid(True, alpha=0.3)

            # 4. SNRæ›²çº¿
            axes[1, 1].plot(epochs, mean_snr, 'm-', linewidth=2)
            axes[1, 1].set_title('Mean SNR', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('SNR (dB)')
            axes[1, 1].grid(True, alpha=0.3)

            # 5. è½¦è¾†æ•°é‡
            axes[2, 0].plot(epochs, vehicle_count, 'c-', linewidth=2)
            axes[2, 0].set_title('Vehicle Count', fontsize=14, fontweight='bold')
            axes[2, 0].set_xlabel('Epoch')
            axes[2, 0].set_ylabel('Number of Vehicles')
            axes[2, 0].grid(True, alpha=0.3)

            # 6. DQNæŸå¤±å¯¹æ¯”
            dqn_plotted = 0
            for dqn_id in sorted(self.dqn_metrics.keys()):
                metrics = self.dqn_metrics[dqn_id]
                if metrics and metrics['loss']:
                    dqn_epochs = range(1, len(metrics['loss']) + 1)
                    dqn_loss = np.array(metrics['loss'])
                    axes[2, 1].plot(dqn_epochs, dqn_loss, label=f'DQN {dqn_id}', alpha=0.7)
                    dqn_plotted += 1

            if dqn_plotted > 0:
                axes[2, 1].set_title('DQN Loss Comparison', fontsize=14, fontweight='bold')
                axes[2, 1].set_xlabel('Epoch')
                axes[2, 1].set_ylabel('Loss')
                axes[2, 1].legend()
                axes[2, 1].grid(True, alpha=0.3)
                if dqn_plotted > 1:  # åªæœ‰å¤šä¸ªDQNæ—¶æ‰ç”¨å¯¹æ•°åæ ‡
                    axes[2, 1].set_yscale('log')
            else:
                axes[2, 1].set_title('DQN Loss Comparison (No Data)', fontsize=14, fontweight='bold')
                axes[2, 1].text(0.5, 0.5, 'No DQN data available',
                                ha='center', va='center', transform=axes[2, 1].transAxes)

            plt.tight_layout()
            plot_path = f"{self.log_dir}/training_metrics.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()

            self.logger.info(f"Performance plots saved to {plot_path}")

        except Exception as e:
            self.logger.error(f"Error generating plots: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

    def _safe_numpy_conversion(self, data):
        """å®‰å…¨è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if isinstance(data, list):
            return np.array(data)
        elif hasattr(data, 'detach'):
            return data.detach().numpy()
        elif hasattr(data, 'numpy'):
            return data.numpy()
        else:
            return np.array([float(x) for x in data])

    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæŠ¥å‘Š - ä¿®å¤ç‰ˆ"""
        try:
            report_path = f"{self.log_dir}/training_report.md"

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(self._generate_report_content())

            self.logger.info(f"Training report generated: {report_path}")

        except Exception as e:
            self.logger.error(f"Error generating report: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

    def _generate_report_content(self):
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹ - ä¿®å¤ç‰ˆ"""
        if not self.metrics['epoch']:
            return "# è®­ç»ƒæŠ¥å‘Š\n\næš‚æ— è®­ç»ƒæ•°æ®"

        # å®‰å…¨è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œè®¡ç®—
        try:
            mean_loss = self._safe_numpy_conversion(self.metrics['mean_loss'])
            cumulative_reward = self._safe_numpy_conversion(self.metrics['cumulative_reward'])
            mean_delay = self._safe_numpy_conversion(self.metrics['mean_delay'])
            mean_snr = self._safe_numpy_conversion(self.metrics['mean_snr'])
            vehicle_count = self._safe_numpy_conversion(self.metrics['vehicle_count'])

            content = f"""
    # å¼ºåŒ–å­¦ä¹ è®­ç»ƒæŠ¥å‘Š

    ## è®­ç»ƒæ¦‚è§ˆ

    - **è®­ç»ƒå¼€å§‹æ—¶é—´**: {self.training_stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
    - **æ€»è®­ç»ƒè½®æ¬¡**: {self.training_stats['total_epochs']}
    - **æœ€ä½³å¥–åŠ±**: {self.training_stats['best_reward']:.4f} (Epoch {self.training_stats['best_epoch']})
    - **æ”¶æ•›è½®æ¬¡**: {self.training_stats.get('convergence_epoch', 'N/A')}
    - **æœ€ç»ˆæŸå¤±**: {mean_loss[-1]:.6f}

    ## æ€§èƒ½æŒ‡æ ‡æ±‡æ€»

    | æŒ‡æ ‡ | å¹³å‡å€¼ | æœ€å°å€¼ | æœ€å¤§å€¼ | æœ€ç»ˆå€¼ | æ ‡å‡†å·® |
    |------|--------|--------|--------|---------|--------|
    | æŸå¤± | {np.mean(mean_loss):.4f} | {np.min(mean_loss):.4f} | {np.max(mean_loss):.4f} | {mean_loss[-1]:.4f} | {np.std(mean_loss):.4f} |
    | å¥–åŠ± | {np.mean(cumulative_reward):.4f} | {np.min(cumulative_reward):.4f} | {np.max(cumulative_reward):.4f} | {cumulative_reward[-1]:.4f} | {np.std(cumulative_reward):.4f} |
    | å»¶è¿Ÿ(s) | {np.mean(mean_delay):.6f} | {np.min(mean_delay):.6f} | {np.max(mean_delay):.6f} | {mean_delay[-1]:.6f} | {np.std(mean_delay):.6f} |
    | SNR(dB) | {np.mean(mean_snr):.2f} | {np.min(mean_snr):.2f} | {np.max(mean_snr):.2f} | {mean_snr[-1]:.2f} | {np.std(mean_snr):.2f} |
    | è½¦è¾†æ•° | {np.mean(vehicle_count):.1f} | {np.min(vehicle_count):.0f} | {np.max(vehicle_count):.0f} | {vehicle_count[-1]:.0f} | {np.std(vehicle_count):.1f} |

    ## è®­ç»ƒæ›²çº¿



    ## DQNæ€§èƒ½åˆ†æ

    """
        except Exception as e:
            content = f"# è®­ç»ƒæŠ¥å‘Š\n\né”™è¯¯ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯: {e}\n\n"

        # ä¿®å¤DQNæ€§èƒ½åˆ†æéƒ¨åˆ†
        for dqn_id in sorted(self.dqn_metrics.keys()):
            metrics = self.dqn_metrics[dqn_id]
            if metrics and metrics['loss']:
                try:
                    dqn_loss = self._safe_numpy_conversion(metrics['loss'])
                    dqn_reward = self._safe_numpy_conversion(metrics['reward'])
                    dqn_vehicle_count = self._safe_numpy_conversion(metrics['vehicle_count'])
                    dqn_snr = self._safe_numpy_conversion(metrics['snr'])
                    dqn_delay = self._safe_numpy_conversion(metrics['delay'])

                    # ä¿®å¤epsilonå€¼çš„å¤„ç†
                    epsilon_value = 0.0
                    if metrics['epsilon']:
                        epsilon_value = metrics['epsilon'][-1] if isinstance(metrics['epsilon'][-1],
                                                                             (int, float)) else 0.0

                    content += f"""
    ### DQN {dqn_id}
    - **å¹³å‡æŸå¤±**: {np.mean(dqn_loss):.4f}
    - **æœ€ç»ˆæŸå¤±**: {dqn_loss[-1]:.4f}
    - **å¹³å‡å¥–åŠ±**: {np.mean(dqn_reward):.3f}
    - **æœåŠ¡è½¦è¾†æ•°**: {np.mean(dqn_vehicle_count):.1f}
    - **æœ€ç»ˆÎµå€¼**: {epsilon_value:.3f}
    - **å¹³å‡SNR**: {np.mean(dqn_snr):.2f} dB
    - **å¹³å‡å»¶è¿Ÿ**: {np.mean(dqn_delay):.6f} s

    """
                except Exception as e:
                    content += f"""
    ### DQN {dqn_id}
    - **é”™è¯¯**: æ— æ³•è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ ({str(e)})

    """

        content += """
    ## æ”¶æ•›åˆ†æ

    """

        if self.training_stats.get('convergence_epoch'):
            content += f"- æ¨¡å‹åœ¨ **Epoch {self.training_stats['convergence_epoch']}** æ”¶æ•›\n"
            content += f"- æœ€ç»ˆæŸå¤±: {self.training_stats['final_loss']:.6f}\n"
        else:
            content += "- æ¨¡å‹æœªå®Œå…¨æ”¶æ•›ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´è¶…å‚æ•°\n"

        content += f"""
    ## å»ºè®®

    åŸºäºå½“å‰è®­ç»ƒç»“æœï¼Œå»ºè®®ï¼š
    1. {'ç»§ç»­ä¼˜åŒ–å¥–åŠ±å‡½æ•°' if self.metrics['cumulative_reward'] and self.metrics['cumulative_reward'][-1] < 0 else 'å¥–åŠ±å‡½æ•°è®¾è®¡è‰¯å¥½'}
    2. {'è°ƒæ•´å­¦ä¹ ç‡æˆ–æ¢ç´¢ç­–ç•¥' if self.metrics['mean_loss'] and np.std(np.array(self.metrics['mean_loss'])) > 1.0 else 'è®­ç»ƒè¿‡ç¨‹ç¨³å®š'}
    3. {'æ£€æŸ¥ä¿¡é“æ¨¡å‹å‚æ•°' if self.metrics['mean_snr'] and np.mean(np.array(self.metrics['mean_snr'])) < 10 else 'SNRæ€§èƒ½è‰¯å¥½'}

    ---

    *æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
    """

        return content

    def finalize(self):
        """å®Œæˆè®­ç»ƒï¼Œä¿å­˜æ‰€æœ‰ç»“æœ"""
        try:
            self.save_metrics_to_csv()
            self.generate_plots()
            self.generate_report()

            training_time = (datetime.now() - self.training_stats['start_time']).total_seconds()
            self.logger.info(f"Training completed in {training_time:.2f} seconds. All results saved to {self.log_dir}")

        except Exception as e:
            self.logger.error(f"Error during finalization: {e}")
            import traceback
            self.logger.error(traceback.format_exc())


# å…¼å®¹æ€§å‡½æ•°
def debug_print(msg):
    global_logger.logger.info(msg)


def debug(msg):
    global_logger.logger.debug(msg)


def set_debug_mode(mode):
    if mode:
        global_logger.logger.setLevel(logging.DEBUG)
    else:
        global_logger.logger.setLevel(logging.INFO)


# å…¨å±€æ—¥å¿—å®ä¾‹
=======
# -*- coding: utf-8 -*-
# logger.py
import logging
import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict


class TrainingLogger:
    """
    ä¸“ä¸šçš„è®­ç»ƒæ—¥å¿—è®°å½•å™¨ - ä¿®å¤ç‰ˆ
    """

    def __init__(self, log_dir="training_results"):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)

        self._setup_logging()
        self._init_metrics_storage()

        self.logger.info("TrainingLogger initialized")
        self.logger.info(f"Log directory: {os.path.abspath(log_dir)}")

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        self.logger = logging.getLogger('RL_Training')
        self.logger.setLevel(logging.INFO)

        # é˜²æ­¢é‡å¤æ·»åŠ handler
        if self.logger.handlers:
            self.logger.handlers.clear()

        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y/%m/%d %H:%M:%S'
        )

        # æ–‡ä»¶handler
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_handler = logging.FileHandler(f'{self.log_dir}/training_{timestamp}.log')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(formatter)

        # æ§åˆ¶å°handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(formatter)

        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

    def _init_metrics_storage(self):
        """åˆå§‹åŒ–æŒ‡æ ‡å­˜å‚¨ç»“æ„"""
        self.metrics = {
            'epoch': [],
            'cumulative_reward': [],
            'mean_loss': [],
            'mean_delay': [],
            'mean_snr': [],
            'vehicle_count': [],
            'timestamp': []
        }

        self.dqn_metrics = defaultdict(lambda: {
            'loss': [],
            'reward': [],
            'epsilon': [],
            'vehicle_count': [],
            'snr': [],
            'delay': []
        })

        self.training_stats = {
            'start_time': datetime.now(),
            'total_epochs': 0,
            'best_reward': -float('inf'),
            'best_epoch': 0,
            'convergence_epoch': None
        }

    def _convert_tensor_to_float(self, value):
        """å®‰å…¨è½¬æ¢PyTorchå¼ é‡ä¸ºfloat"""
        if hasattr(value, 'detach'):
            # å¦‚æœæ˜¯PyTorchå¼ é‡
            return value.detach().item() if value.numel() == 1 else float(value.detach().mean())
        elif hasattr(value, 'numpy'):
            # å¦‚æœæ˜¯TensorFlowå¼ é‡æˆ–å…¶ä»–
            return float(value)
        else:
            # å¦‚æœæ˜¯æ™®é€šæ•°å€¼
            return float(value)

    def _convert_tensor_to_int(self, value):
        """å®‰å…¨è½¬æ¢PyTorchå¼ é‡ä¸ºint"""
        if hasattr(value, 'detach'):
            # å¦‚æœæ˜¯PyTorchå¼ é‡
            return int(value.detach().item() if value.numel() == 1 else int(value.detach().mean()))
        elif hasattr(value, 'numpy'):
            # å¦‚æœæ˜¯TensorFlowå¼ é‡æˆ–å…¶ä»–
            return int(value)
        else:
            # å¦‚æœæ˜¯æ™®é€šæ•°å€¼
            return int(value)

    def log_epoch(self, epoch, cumulative_reward, mean_loss, mean_delay, mean_snr, vehicle_count):
        """è®°å½•æ¯ä¸ªepochçš„å…¨å±€æŒ‡æ ‡ - ä¿®å¤ç‰ˆ"""
        # å®‰å…¨è½¬æ¢æ‰€æœ‰å€¼ä¸ºæ­£ç¡®çš„ç±»å‹
        cumulative_reward_float = self._convert_tensor_to_float(cumulative_reward)
        mean_loss_float = self._convert_tensor_to_float(mean_loss)
        mean_delay_float = self._convert_tensor_to_float(mean_delay)
        mean_snr_float = self._convert_tensor_to_float(mean_snr)
        vehicle_count_int = self._convert_tensor_to_int(vehicle_count)

        self.metrics['epoch'].append(epoch)
        self.metrics['cumulative_reward'].append(cumulative_reward_float)
        self.metrics['mean_loss'].append(mean_loss_float)
        self.metrics['mean_delay'].append(mean_delay_float)
        self.metrics['mean_snr'].append(mean_snr_float)
        self.metrics['vehicle_count'].append(vehicle_count_int)
        self.metrics['timestamp'].append(datetime.now())

        # æ›´æ–°è®­ç»ƒç»Ÿè®¡
        self.training_stats['total_epochs'] = epoch
        if cumulative_reward_float > self.training_stats['best_reward']:
            self.training_stats['best_reward'] = cumulative_reward_float
            self.training_stats['best_epoch'] = epoch

        self.logger.info(
            f"Epoch {epoch:4d} | "
            f"Loss: {mean_loss_float:7.4f} | "
            f"Reward: {cumulative_reward_float:8.3f} | "
            f"Delay: {mean_delay_float:8.6f}s | "
            f"SNR: {mean_snr_float:6.2f}dB | "
            f"Vehicles: {vehicle_count_int:3d}"
        )

    def log_dqn_performance(self, dqn_id, metrics_dict):
        """è®°å½•å•ä¸ªDQNçš„æ€§èƒ½æŒ‡æ ‡ - ä¿®å¤ç‰ˆ"""
        # å®‰å…¨è½¬æ¢æ‰€æœ‰æŒ‡æ ‡å€¼ä¸ºæ­£ç¡®çš„ç±»å‹
        safe_metrics = {}
        for metric_name, value in metrics_dict.items():
            if metric_name in ['vehicle_count']:
                # è½¦è¾†æ•°é‡éœ€è¦æ•´æ•°
                safe_metrics[metric_name] = self._convert_tensor_to_int(value)
            else:
                # å…¶ä»–æŒ‡æ ‡ç”¨æµ®ç‚¹æ•°
                safe_metrics[metric_name] = self._convert_tensor_to_float(value)

        for metric_name, value in safe_metrics.items():
            if metric_name in self.dqn_metrics[dqn_id]:
                self.dqn_metrics[dqn_id][metric_name].append(value)

        # ä¿®å¤æ ¼å¼åŒ–å­—ç¬¦ä¸² - æ ¹æ®ç±»å‹ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼
        vehicle_count = safe_metrics.get('vehicle_count', 0)
        if isinstance(vehicle_count, (int, np.integer)):
            vehicle_format = f"{vehicle_count:2d}"
        else:
            vehicle_format = f"{int(vehicle_count):2d}"

        self.logger.debug(
            f"DQN {dqn_id:2d} | "
            f"Loss: {safe_metrics.get('loss', 0):7.4f} | "
            f"Reward: {safe_metrics.get('reward', 0):8.3f} | "
            f"Epsilon: {safe_metrics.get('epsilon', 0):5.3f} | "
            f"Vehicles: {vehicle_format}"
        )

    def log_convergence(self, epoch, final_loss):
        """è®°å½•æ”¶æ•›ä¿¡æ¯"""
        final_loss_float = self._convert_tensor_to_float(final_loss)
        self.training_stats['convergence_epoch'] = epoch
        self.training_stats['final_loss'] = final_loss_float

        self.logger.info(f"ğŸš€ CONVERGENCE ACHIEVED at epoch {epoch} with final loss {final_loss_float:.6f}")

    def _ensure_consistent_array_lengths(self):
        """ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´ - ä¿®å¤é•¿åº¦ä¸ä¸€è‡´é—®é¢˜"""
        max_length = max(len(arr) for arr in self.metrics.values() if arr)

        for key in self.metrics:
            current_length = len(self.metrics[key])
            if current_length < max_length:
                # ç”¨æœ€åä¸€ä¸ªå€¼å¡«å……ç¼ºå¤±çš„æ•°æ®
                fill_value = self.metrics[key][-1] if self.metrics[key] else 0
                self.metrics[key].extend([fill_value] * (max_length - current_length))
                self.logger.warning(f"Fixed array length for {key}: {current_length} -> {max_length}")

    def save_metrics_to_csv(self):
        """å°†æŒ‡æ ‡ä¿å­˜ä¸ºCSVæ–‡ä»¶ - ä¿®å¤ç‰ˆ"""
        try:
            # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
            self._ensure_consistent_array_lengths()

            # ä¿å­˜å…¨å±€æŒ‡æ ‡
            global_df = pd.DataFrame(self.metrics)
            global_csv_path = f"{self.log_dir}/global_metrics.csv"
            global_df.to_csv(global_csv_path, index=False)
            self.logger.info(f"Global metrics saved to {global_csv_path}")

            # ä¿å­˜DQNæŒ‡æ ‡
            dqn_count = 0
            for dqn_id, metrics in self.dqn_metrics.items():
                if metrics and metrics['loss']:  # åªä¿å­˜æœ‰æ•°æ®çš„DQN
                    # ç¡®ä¿DQNæŒ‡æ ‡æ•°ç»„é•¿åº¦ä¸€è‡´
                    max_dqn_length = max(len(arr) for arr in metrics.values() if arr)
                    for key in metrics:
                        if len(metrics[key]) < max_dqn_length:
                            fill_value = metrics[key][-1] if metrics[key] else 0
                            metrics[key].extend([fill_value] * (max_dqn_length - len(metrics[key])))

                    dqn_df = pd.DataFrame(metrics)
                    dqn_df['epoch'] = range(1, len(dqn_df) + 1)
                    dqn_csv_path = f"{self.log_dir}/dqn_{dqn_id}_metrics.csv"
                    dqn_df.to_csv(dqn_csv_path, index=False)
                    dqn_count += 1

            self.logger.info(f"Saved metrics for {dqn_count} DQNs to CSV files")

        except Exception as e:
            self.logger.error(f"Error saving CSV: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

    def generate_plots(self):
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨ - ä¿®å¤ç‰ˆ"""
        try:
            # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
            self._ensure_consistent_array_lengths()

            # è®¾ç½®ç»˜å›¾æ ·å¼
            plt.style.use('default')
            sns.set_palette("husl")

            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(3, 2, figsize=(15, 12))
            fig.suptitle('Training Performance Metrics', fontsize=16, fontweight='bold')

            # ç¡®ä¿æœ‰æ•°æ®å¯ç»˜åˆ¶
            if not self.metrics['epoch']:
                self.logger.warning("No data available for plotting")
                return

            # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆå®‰å…¨è½¬æ¢ï¼‰
            epochs = np.array(self.metrics['epoch'])
            mean_loss = np.array(self.metrics['mean_loss'])
            cumulative_reward = np.array(self.metrics['cumulative_reward'])
            mean_delay = np.array(self.metrics['mean_delay'])
            mean_snr = np.array(self.metrics['mean_snr'])
            vehicle_count = np.array(self.metrics['vehicle_count'])

            # 1. æŸå¤±æ›²çº¿
            axes[0, 0].plot(epochs, mean_loss, 'b-', linewidth=2)
            axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)
            if len(mean_loss) > 0 and max(mean_loss) > min(mean_loss) * 10:
                axes[0, 0].set_yscale('log')

            # 2. å¥–åŠ±æ›²çº¿
            axes[0, 1].plot(epochs, cumulative_reward, 'g-', linewidth=2)
            axes[0, 1].set_title('Cumulative Reward', fontsize=14, fontweight='bold')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Reward')
            axes[0, 1].grid(True, alpha=0.3)

            # 3. å»¶è¿Ÿæ›²çº¿
            axes[1, 0].plot(epochs, mean_delay, 'r-', linewidth=2)
            axes[1, 0].set_title('Mean Delay', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Delay (s)')
            axes[1, 0].grid(True, alpha=0.3)

            # 4. SNRæ›²çº¿
            axes[1, 1].plot(epochs, mean_snr, 'm-', linewidth=2)
            axes[1, 1].set_title('Mean SNR', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('SNR (dB)')
            axes[1, 1].grid(True, alpha=0.3)

            # 5. è½¦è¾†æ•°é‡
            axes[2, 0].plot(epochs, vehicle_count, 'c-', linewidth=2)
            axes[2, 0].set_title('Vehicle Count', fontsize=14, fontweight='bold')
            axes[2, 0].set_xlabel('Epoch')
            axes[2, 0].set_ylabel('Number of Vehicles')
            axes[2, 0].grid(True, alpha=0.3)

            # 6. DQNæŸå¤±å¯¹æ¯”
            dqn_plotted = 0
            for dqn_id in sorted(self.dqn_metrics.keys()):
                metrics = self.dqn_metrics[dqn_id]
                if metrics and metrics['loss']:
                    dqn_epochs = range(1, len(metrics['loss']) + 1)
                    dqn_loss = np.array(metrics['loss'])
                    axes[2, 1].plot(dqn_epochs, dqn_loss, label=f'DQN {dqn_id}', alpha=0.7)
                    dqn_plotted += 1

            if dqn_plotted > 0:
                axes[2, 1].set_title('DQN Loss Comparison', fontsize=14, fontweight='bold')
                axes[2, 1].set_xlabel('Epoch')
                axes[2, 1].set_ylabel('Loss')
                axes[2, 1].legend()
                axes[2, 1].grid(True, alpha=0.3)
                if dqn_plotted > 1:  # åªæœ‰å¤šä¸ªDQNæ—¶æ‰ç”¨å¯¹æ•°åæ ‡
                    axes[2, 1].set_yscale('log')
            else:
                axes[2, 1].set_title('DQN Loss Comparison (No Data)', fontsize=14, fontweight='bold')
                axes[2, 1].text(0.5, 0.5, 'No DQN data available',
                                ha='center', va='center', transform=axes[2, 1].transAxes)

            plt.tight_layout()
            plot_path = f"{self.log_dir}/training_metrics.png"
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()

            self.logger.info(f"Performance plots saved to {plot_path}")

        except Exception as e:
            self.logger.error(f"Error generating plots: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

    def _safe_numpy_conversion(self, data):
        """å®‰å…¨è½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if isinstance(data, list):
            return np.array(data)
        elif hasattr(data, 'detach'):
            return data.detach().numpy()
        elif hasattr(data, 'numpy'):
            return data.numpy()
        else:
            return np.array([float(x) for x in data])

    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæŠ¥å‘Š - ä¿®å¤ç‰ˆ"""
        try:
            report_path = f"{self.log_dir}/training_report.md"

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(self._generate_report_content())

            self.logger.info(f"Training report generated: {report_path}")

        except Exception as e:
            self.logger.error(f"Error generating report: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

    def _generate_report_content(self):
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹ - ä¿®å¤ç‰ˆ"""
        if not self.metrics['epoch']:
            return "# è®­ç»ƒæŠ¥å‘Š\n\næš‚æ— è®­ç»ƒæ•°æ®"

        # å®‰å…¨è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œè®¡ç®—
        try:
            mean_loss = self._safe_numpy_conversion(self.metrics['mean_loss'])
            cumulative_reward = self._safe_numpy_conversion(self.metrics['cumulative_reward'])
            mean_delay = self._safe_numpy_conversion(self.metrics['mean_delay'])
            mean_snr = self._safe_numpy_conversion(self.metrics['mean_snr'])
            vehicle_count = self._safe_numpy_conversion(self.metrics['vehicle_count'])

            content = f"""
    # å¼ºåŒ–å­¦ä¹ è®­ç»ƒæŠ¥å‘Š

    ## è®­ç»ƒæ¦‚è§ˆ

    - **è®­ç»ƒå¼€å§‹æ—¶é—´**: {self.training_stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}
    - **æ€»è®­ç»ƒè½®æ¬¡**: {self.training_stats['total_epochs']}
    - **æœ€ä½³å¥–åŠ±**: {self.training_stats['best_reward']:.4f} (Epoch {self.training_stats['best_epoch']})
    - **æ”¶æ•›è½®æ¬¡**: {self.training_stats.get('convergence_epoch', 'N/A')}
    - **æœ€ç»ˆæŸå¤±**: {mean_loss[-1]:.6f}

    ## æ€§èƒ½æŒ‡æ ‡æ±‡æ€»

    | æŒ‡æ ‡ | å¹³å‡å€¼ | æœ€å°å€¼ | æœ€å¤§å€¼ | æœ€ç»ˆå€¼ | æ ‡å‡†å·® |
    |------|--------|--------|--------|---------|--------|
    | æŸå¤± | {np.mean(mean_loss):.4f} | {np.min(mean_loss):.4f} | {np.max(mean_loss):.4f} | {mean_loss[-1]:.4f} | {np.std(mean_loss):.4f} |
    | å¥–åŠ± | {np.mean(cumulative_reward):.4f} | {np.min(cumulative_reward):.4f} | {np.max(cumulative_reward):.4f} | {cumulative_reward[-1]:.4f} | {np.std(cumulative_reward):.4f} |
    | å»¶è¿Ÿ(s) | {np.mean(mean_delay):.6f} | {np.min(mean_delay):.6f} | {np.max(mean_delay):.6f} | {mean_delay[-1]:.6f} | {np.std(mean_delay):.6f} |
    | SNR(dB) | {np.mean(mean_snr):.2f} | {np.min(mean_snr):.2f} | {np.max(mean_snr):.2f} | {mean_snr[-1]:.2f} | {np.std(mean_snr):.2f} |
    | è½¦è¾†æ•° | {np.mean(vehicle_count):.1f} | {np.min(vehicle_count):.0f} | {np.max(vehicle_count):.0f} | {vehicle_count[-1]:.0f} | {np.std(vehicle_count):.1f} |

    ## è®­ç»ƒæ›²çº¿



    ## DQNæ€§èƒ½åˆ†æ

    """
        except Exception as e:
            content = f"# è®­ç»ƒæŠ¥å‘Š\n\né”™è¯¯ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯: {e}\n\n"

        # ä¿®å¤DQNæ€§èƒ½åˆ†æéƒ¨åˆ†
        for dqn_id in sorted(self.dqn_metrics.keys()):
            metrics = self.dqn_metrics[dqn_id]
            if metrics and metrics['loss']:
                try:
                    dqn_loss = self._safe_numpy_conversion(metrics['loss'])
                    dqn_reward = self._safe_numpy_conversion(metrics['reward'])
                    dqn_vehicle_count = self._safe_numpy_conversion(metrics['vehicle_count'])
                    dqn_snr = self._safe_numpy_conversion(metrics['snr'])
                    dqn_delay = self._safe_numpy_conversion(metrics['delay'])

                    # ä¿®å¤epsilonå€¼çš„å¤„ç†
                    epsilon_value = 0.0
                    if metrics['epsilon']:
                        epsilon_value = metrics['epsilon'][-1] if isinstance(metrics['epsilon'][-1],
                                                                             (int, float)) else 0.0

                    content += f"""
    ### DQN {dqn_id}
    - **å¹³å‡æŸå¤±**: {np.mean(dqn_loss):.4f}
    - **æœ€ç»ˆæŸå¤±**: {dqn_loss[-1]:.4f}
    - **å¹³å‡å¥–åŠ±**: {np.mean(dqn_reward):.3f}
    - **æœåŠ¡è½¦è¾†æ•°**: {np.mean(dqn_vehicle_count):.1f}
    - **æœ€ç»ˆÎµå€¼**: {epsilon_value:.3f}
    - **å¹³å‡SNR**: {np.mean(dqn_snr):.2f} dB
    - **å¹³å‡å»¶è¿Ÿ**: {np.mean(dqn_delay):.6f} s

    """
                except Exception as e:
                    content += f"""
    ### DQN {dqn_id}
    - **é”™è¯¯**: æ— æ³•è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ ({str(e)})

    """

        content += """
    ## æ”¶æ•›åˆ†æ

    """

        if self.training_stats.get('convergence_epoch'):
            content += f"- æ¨¡å‹åœ¨ **Epoch {self.training_stats['convergence_epoch']}** æ”¶æ•›\n"
            content += f"- æœ€ç»ˆæŸå¤±: {self.training_stats['final_loss']:.6f}\n"
        else:
            content += "- æ¨¡å‹æœªå®Œå…¨æ”¶æ•›ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´è¶…å‚æ•°\n"

        content += f"""
    ## å»ºè®®

    åŸºäºå½“å‰è®­ç»ƒç»“æœï¼Œå»ºè®®ï¼š
    1. {'ç»§ç»­ä¼˜åŒ–å¥–åŠ±å‡½æ•°' if self.metrics['cumulative_reward'] and self.metrics['cumulative_reward'][-1] < 0 else 'å¥–åŠ±å‡½æ•°è®¾è®¡è‰¯å¥½'}
    2. {'è°ƒæ•´å­¦ä¹ ç‡æˆ–æ¢ç´¢ç­–ç•¥' if self.metrics['mean_loss'] and np.std(np.array(self.metrics['mean_loss'])) > 1.0 else 'è®­ç»ƒè¿‡ç¨‹ç¨³å®š'}
    3. {'æ£€æŸ¥ä¿¡é“æ¨¡å‹å‚æ•°' if self.metrics['mean_snr'] and np.mean(np.array(self.metrics['mean_snr'])) < 10 else 'SNRæ€§èƒ½è‰¯å¥½'}

    ---

    *æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
    """

        return content

    def finalize(self):
        """å®Œæˆè®­ç»ƒï¼Œä¿å­˜æ‰€æœ‰ç»“æœ"""
        try:
            self.save_metrics_to_csv()
            self.generate_plots()
            self.generate_report()

            training_time = (datetime.now() - self.training_stats['start_time']).total_seconds()
            self.logger.info(f"Training completed in {training_time:.2f} seconds. All results saved to {self.log_dir}")

        except Exception as e:
            self.logger.error(f"Error during finalization: {e}")
            import traceback
            self.logger.error(traceback.format_exc())


# å…¼å®¹æ€§å‡½æ•°
def debug_print(msg):
    global_logger.logger.info(msg)


def debug(msg):
    global_logger.logger.debug(msg)


def set_debug_mode(mode):
    if mode:
        global_logger.logger.setLevel(logging.DEBUG)
    else:
        global_logger.logger.setLevel(logging.INFO)


# å…¨å±€æ—¥å¿—å®ä¾‹
>>>>>>> d177c06cd79adbc5bd91dbc020ffa10ee606353d
global_logger = TrainingLogger()